- [=======第二部分 分布式数据系统](#第二部分-分布式数据系统)
- [第五章：数据复制](#第五章数据复制)
  - [主从复制](#主从复制)
    - [复制日志的实现](#复制日志的实现)
    - [复制滞后问题](#复制滞后问题)
      - [**问题：读自己的写（读写一致性）**](#问题读自己的写读写一致性)
      - [**问题：单调读（单调读一致性）**](#问题单调读单调读一致性)
      - [**问题3：前缀一致读**](#问题3前缀一致读)
      - [**复制滞后的解决方案**](#复制滞后的解决方案)
  - [多主节点复制](#多主节点复制)
    - [适用场景](#适用场景)
    - [处理写冲突](#处理写冲突)
    - [拓扑结构](#拓扑结构)
  - [无主节点复制](#无主节点复制)
    - [失效节点与数据恢复](#失效节点与数据恢复)
    - [Quorum一致性局限性](#quorum一致性局限性)
    - [检测并发写(再谈写冲突)](#检测并发写再谈写冲突)
      - [**方法1：最后写入者获胜（last write wins,LWW）（丢弃并发写入）**](#方法1最后写入者获胜last-write-winslww丢弃并发写入)
      - [**方法2：通过算法区分并发和Happens-before**](#方法2通过算法区分并发和happens-before)
- [第六章：数据分区](#第六章数据分区)
  - [怎么分区](#怎么分区)
    - [键值数据的分区](#键值数据的分区)
      - [**基于关键字区间分区**](#基于关键字区间分区)
      - [**基于关键字哈希值分区**](#基于关键字哈希值分区)
  - [分区与二级索引](#分区与二级索引)
    - [基于文档分区的二级索引](#基于文档分区的二级索引)
    - [基于词条的二级索引分区](#基于词条的二级索引分区)
  - [分区再平衡](#分区再平衡)
    - [固定数量的分区](#固定数量的分区)
    - [动态分区](#动态分区)
    - [按节点比例分区](#按节点比例分区)
  - [请求路由](#请求路由)
# =======第二部分 分布式数据系统
- 分布式目的
  - 高吞吐。扩展，负载均衡
  - 高可用性。冗余，容错
  - 低延迟。就近服务

- 扩展方式
  - **共享结构（垂直扩展）**
    - **共享内存架构**：单台机子
      - 优点：提供有限的容错能力。例如高端的服务器可以热插拔很多组件（在不关闭机器的情况下更换磁盘，内存模块，甚至是CPU ）
      - 缺点：成本高。成本增长过快甚至超过了线性
    - **共享磁盘架构**：多台服务器，共享磁盘阵列
      - 缺点：资源竞争和锁的开销比较大
  - **无共享结构（水平扩展）**（分布式）：数据分布在多个节点
    - 优点：灵活，高性价比，云趋势。
    - 缺点：复杂

- 数据分布式时，两种常见方式
  - 分区
  - 复制

<div align="center" style="zoom:70%"><img src="./pic/2-1.png"><br><span style="font-size:18px">复制和分区</span></div>



# 第五章：数据复制
- 如果数据不变，复制十分简单。所有的难点都在于那些持续更改的数据。
- 三种流行的复制数据变化的方法：
  - **主从复制**
  - **多主节点复制**
  - **无主节点复制**

## 主从复制
- **副本**：每个保存数据库完整数据集的节点称之为副本
- **工作原理**：
  - 指定某一个副本为**主副本**（或称为主节点）。只能往主节点写。
  - 其他副本全部称为**从副本**（或称为从节点）。主节点更改信息后，发送某种形式的更新数据（称为**复制日志**），从节点获取后应用到本地，且严格保持与主副本**相同的写入顺序**。
  - 读主/副节点都可以。
- 注：主从复制技术也不仅限于数据库，还广泛用于分布式消息队列（Kafka）等。

> 同步复制和异步复制
<div align="center" style="zoom:70%"><img src="./pic/2-2.png"></div>

- **同步复制**
  - 优点：主节点故障，总是可以在从节点访问到最新数据
  - 缺点：同步的从节点无法完成确认，会阻塞。
  - **半同步**：实践中，如果数据库启用了同步复制，通常意味着其中某一个从节点是同步的，而其他节点则是异步模式。万一同步的从节点变得不可用或性能下降，则将另一个异步的从节点提升为同步模式。
- **异步模式**
  - 全异步模式
    - 缺点：持久性无法保证
    - 优点：吞吐性能好

> 如何配置新的从节点
- 步骤
  - 快照
  - 追赶

> 如何处理节点失效
- 从节点
  - 追赶
- 主节点
  - **处理步骤**
    - 确认主节点失效
    - 选举
    - 重新配置系统使主节点生效
  - 问题：
    - **情况1**：使用了异步复制，失效前刚写了数据还没复制；主节点切换；之后原主节点迅速恢复，还未意识角色切换，仍进行复制导致**新主节点收到了冲突的写请求**。
      - 常见解决方案：直接丢了数据。但违背了持久化承诺。
    - **情况2**：有其他数据系统依赖于数据库的内容，并一起协同工作。
      - eg:Redis和MySQL：在GitHub的一个事故中，**某个数据并非完全同步的MySQL从节点被提升为主副本**，数据库使用了自增计数器将主键分配给新创建的行，但是因为新的主节点计数器落后于原主节点（ 即二者并非完全同步），它重新使用了已被原主节点分配出去的某些主键，而恰好这些主键已被外部Redis所引用，结果出现MySQL和Redis之间的不一致，最后**导致了某些私有数据被错误地泄露给了其他用户**
    - **情况3**：**脑裂**，发生两个节点同时都自认为是主节点。它非常危险：两个主节点都可能接受写请求，并且没有很好解决冲突的办法。
      - 解决：强制关闭其中一个。
    - **情况4**：如何设置合适超时检测主节点失效：
      - 太长：恢复时间太长
      - 太短：太多没必要的切换

### 复制日志的实现
- 基于语句的复制
- 基于预写日志（WAL）传输
- 基于行的逻辑日志复制
- 基于触发器的复制
> 基于语句的复制
- 该操作语句作为日志发送给从节点。如SQL上INSERT 、 UPDATE或DELETE语句
- 局限：
  - 调用**非确定性函数**的语句可能会在不同的副本上产生不同的值
  - 如果语句中使用了自增列，或者依赖于数据库的现有数据（如 `update ... where ...`，**副本必须按照完全形同的顺序执行**，否则结果不一样。这**对于多个同时并发执行的事务时，有很大限制**。
  - 有副作用的语句（例如，触发器、存储过程等`[由于每个节点定义不同原因]`），可能会在每个副本上产生不同的副作用

> 基于预写日志（WAL）传输
- 通过发送WAL
- 局限：
  - 太底层，和搜索引擎紧耦合

> 基于行的逻辑日志复制
- **逻辑日志**：复制和存储引擎采用不同的日志格式，这样**复制与存储逻辑剥离**
  - eg:Mysql的`binlog`
- 关系数据库的逻辑日志规则：p153

- 优点：
  - 外部应用程序容易解析
  - 逻辑日志与存储引擎解耦

> 基于触发器的复制
- 上面的都是数据库系统实现，这种是交给了应用层程序
- 需求（更灵活）：
  - 只想复制数据的一部分
  - 想从一种数据库复制到另一种数据库
  - 需要订制、 管理冲突解决逻辑
- 认识：基于触发器的复制通常比其他复制方式开销更高， 也比数据库内 置复制更容易出错，或者暴露一些限制。然而，其高度灵活性仍有用武之地。

### 复制滞后问题
- **本质**：由于**并非所有的写入都反映在从副本上**，如果同时对主节点和从节点发起相同的查询，可能会得到不同的结果。
  - 最终一致性：这种不一致只是一个暂时的状态，如果停止写数据库，经过一段时间之后，从节点最终会赶上并与主节点保持一致。这种效应也被称为**最终一致性**

#### **问题：读自己的写（读写一致性）**
- 情况：用户写了再读，发现白写了
  - 角色：一个客户端
<div align="center" style="zoom:70%"><img src="./pic/2-3.png"></div>

- **写后读一致性(读写一致性)**：其机制就是避免上图所示的场景。
- 如何实现读写一致性，解决方法：
  - 方法1：可能被用户自己修改的，从主节点读取。
    - eg：微博主页，自己的主页从主节点，别人的再从节点读取。
  - 方法2：如果大量数据都可能被用户自己修改，那么这样扩展性失去意义。**跟踪最近更新的时间**，如果更新后一分钟之内（**客户端角度**），则总是在主节点读取；井监控从节点的复制滞后程度，避免从那些滞后时间超过一分钟的从节点读取 
  - 方法3：**客户端**还可以记住最近更新时的时间戳，井附带在读请求中。
    - 时间戳可以是**逻辑时间戳**（例如用来指示写入顺序的日志序列号）或**实际系统时钟**（时钟同步是关键）
  - 如果是多数据中心，更复杂，必须先把请求路由到主节点（写入时的主节点）所在的数据中心。

- 多个终端的时候，面临问题
  - 方法2失效，需要全局共享的元数据
  - 无法保证设备路由后到达同个数据中心。

#### **问题：单调读（单调读一致性）**
- 情况：刷新前看到的，刷新后不见了。
  - 角色，两个客户端

<div align="center" style="zoom:70%"><img src="./pic/2-4.png"></div>

- 单调读一致性：解决这种情况的机制。
- 实现单调读一致性方法：
  - 方法1：确保每个用户总是从固定的同一副本执行读取
    - eg:基于用户 ID的哈希的方怯而不是｜随机选择副本

#### **问题3：前缀一致读**
- 情况：见图，注意多个分区
  - 角色：三个客户端

<div align="center" style="zoom:70%"><img src="./pic/2-5.png"></div>

- 问题本质：如果数据库总是以相同的顺序写入，则读取总是看到一致的序列，不会发生这种反常。然而，**在许多分布式数据库中，不同的 分区 独立运行，因此不存在全局写入顺序**。这就导致当用户从数据库中读数据时，可能会看到数据库的某部分旧值和另一部分新值。
- 保证前缀一致读方法：
  - 确保任何具有因果顺序关系的写人都交给**一个分区**来完成
    - 该方案真实实现效率会大打折扣

#### **复制滞后的解决方案**
- 在使用最终一致性系统时，就该考虑一个问题：**如果复制延迟增加到几分钟甚至几小时，那么应用层的行为会是什么样子**？如果答案是“没问题”， 那没得说。
- 借助应用层：应用层可以提供比底层数据库更强有力的保证
  - 缺点：开发人员负担
- 使用事务：如果应用程序开发人员不必担心这么多底层的复制问题，而是**假定数据库在“做正确的事情”，情况就变得很简单**。而**这也是事务存在的原因**，事务是数据库提供更强保证的一种方式。

## 多主节点复制

<div align="center" style="zoom:70%"><img src="./pic/2-6.png"></div>

### 适用场景
> 多数据中心
- 方式：在每个数据中心内，采用常规的**主从复制**方案；而在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。（通常各个主节点之间用**异步复制**，不然的话就没意思了）
- 其他主节点相当于该主节点的从节点。
- 多数据中心目的
  - 更强可用性：容忍数据中心失效
  - 更低延迟：更近服务

- 多数据中心下，但主节点和多主节点的差异p161
  - 性能
  - 容忍数据中心失效
  - 容忍网络问题

> 离线客户端操作
- 比如手机、笔记本上备忘录，为了支持离线。每个设备都有一个充当主节点的本地数据库。这其实就是极端情况下，数据中心之间的多主复制

> 写作编辑
- 比如腾讯文档
  - 通常不会将协作编辑完全等价于数据库复制问题，但二者确实有很多相似之处。
- 当一个用户编辑文档时，所做的更改会立即应用到本地副本，然后异步复制到服务器以及编辑同一文档的其他用户
- 如何确保不会发生编辑冲突：
  - 应用程序获得锁后才能编辑。可编辑的粒度需要非常小
  - 这种协作模式相当于主从复制模型下在主节点上执行事务操作。

### 处理写冲突
- 单主节点主要是读方面的冲突，多主节点更突出的是写冲突
- 情况：多个主节点在复制前，发生写同一个数据
  - 一致性破坏了。不知道该弄哪个，两难。解决其中一个其实就好了。
<div align="center" style="zoom:70%"><img src="./pic/2-7.png"></div>

- 上图的问题是发了ok了，后来却发现并不ok（检测到冲突）。
- **发生写冲突的本质**：在整体系统中，写是无序的。

- 主从结构为什么没事
  - **因为写有序**，因为第二个请求要么被阻塞，要么无效（比如不存在A了，无效后可以通知用户）
  - 不是也无效了么，为什么没事？
    - **没有破坏一致性**


> 各个主节点使用同步复制
- 可以，因为同步复制后才发ok通知用户。但是这样做将会失去多主节点的主优势

> 避免冲突
- 处理冲突**最理想**的策略是**避免发生冲突**
- 比如：
  - 让用户更新自己数据的同时都是再同一个主节点。

> 收敛于一致性
- 就是让冲突最后被解决
  - 用户自己解决
    - 记录下来，下次让用户选择
  - 数据库自己解决（流行）
    - 某种机制选择一个。比如主节点权重，时间戳
  - 交给应用程序进行逻辑判断，可能告知用户

> 自定义冲突解决逻辑
- 解决冲突**最合适**的方式可能还是**依靠应用层**
- 现状：**有工具**
  - **写入是执行**：写入时发现冲突，就触发冲突处理程序
  - **读取时执行**：检测到冲突，记下来，下次读取时，给出多个版本到应用层。应用层可以提示用户或者自己解决冲突，并将最后结果返回到数据库。

### 拓扑结构
<div align="center" style="zoom:70%"><img src="./pic/2-8.png"></div>

- 针对环形和星型的问题
  - **防止数据变更无限循环**：每个节点需要赋予一个唯一的标识符，在复制日志中的每个写请求都标记了已通过的节点标识符
  - **防止节点故障对其他节点影响**：重新配置拓扑结构
- 针对全连接拓扑的问题
  - **复制日志到达乱序**，导致复制日志之间的覆盖。如下图
    - 解决：版本向量
<div align="center" style="zoom:70%"><img src="./pic/2-9.png"></div>

## 无主节点复制
- 亚马逊: **Dynamo系统**。使得无主复制流行。

### 失效节点与数据恢复
> 数据恢复
- 读修复
  - 被读到都发现过期才更新
- 反熵修复
  - 一个后台进程查找副本间差异并修复。  


> 读写quorum
- 法定票数读
  - `n`：n个副本
  - `w`：写入需要w个节点确认
  - `r`：读取必须至少查询r个
  - **约束**：`w + r > n`，则读取的节点中一定有最新值。
    - 保证写读有交
<div align="center" style="zoom:70%"><img src="./pic/2-10.png"></div>


- 假设可用节点为`n*`，则
  - `n* >= w`：可写
  - `n* >= r`：可读
- 常见设置：设置n为某奇数（通常为3或5）, `w=r=(n+1)/2` （向上舍入）
  - 可以根据业务灵活配置。r越小读越快，w越小写越快

### Quorum一致性局限性
- 建议：**最好不要把参数w和r视为绝对的保证**，而是一种灵活可调的读取新值的概率。
- 一致性面临的问题：
  - 写冲突。（两个同时写）解决可以借鉴多主结构写冲突处理
    - 本质也是写无序
  - 写读同时。（注意不是写后读）在写的同时被别人读了，读取到的是新值还是旧值未知。
  - 写失败，但是不能回滚。写入的副本数少于w，失败了（不返回ok），但是在有些节点已经生效，不能回滚。
  - 存有新值节点失效，但是恢复数据来自某个旧值（还有这种情况？）。则总的新值副本可能低于w。（注：有点牵强啊）
  - `sloppy quorum`情况

> 监控旧值
- 主从结构做法
  - 因为写入都是遵从相同的顺序，每个节点都维护了复制日志执行的当前**偏移量**。
  - 监控主节点和从节点的偏移量差异就好了
- 无主结构做法
  - 写无序，监控困难。
  - 尚在研究。已有做法：根据参数 n, w和r来预测读到旧值的期望百分比（有兴趣再了解下）


- 作者：将旧值监控纳入到数据库标准指标集中还是很有必要。要知道，最终一致性其实是个非常**模糊**的保证，从可操作性上讲， **量化究竟何为“最终”很有实际价值**。
  - 后面体会

> 宽松的quorum（sloppy quorum）与数据回传
- 容错能力并不是和期待的那样。**一个网络中断可以很容易切断一个客户端到多数数据库节点的链接。** 尽管这些集群的节点是活着的，但是对于网络异常的客户端，无疑等同于整体集群几乎失效。怎么办。两种选择
  - 1.告诉客户端出错
  - 2.放松的仲裁+数据回传。（sloppy quorum）
    - **放松的仲裁**：暂时先写入到其他可用节点（注：这些几点不再n的集合里）
    - **数据回传**：网络问题解决后，临时节点上的数据移交到原始节点。

- **sloppy quorum**
  - 优点：提高写的可用性
  - 缺点：一致性缺陷。即使`w+r>n`，也不能保证读到的一定是最新的。（注：sloppy quorum写入的可能暂时不被读到）

> 多数据中心操作
- p175
- 两类
  - Cassandra和Voldemort
  - Riak

### 检测并发写(再谈写冲突)
- 写冲突情况：对**相同主键**同时发起写操作

- **本质**：写无序
- **核心问题**：网络延迟和局部失效，请求在不同的节点上可能会呈现不同的顺序

> 无主结构写冲突例子
- 节点2认为X的最终值是B ，而其他节点认为值是A
<div align="center" style="zoom:70%"><img src="./pic/2-11.png"></div>



#### **方法1：最后写入者获胜（last write wins,LWW）（丢弃并发写入）**
- **关键点**：如何定义“最新”
  - eg:时间戳
- LWW可以实现最终收敛的目标，但是以**牺牲数据持久性**为代价。
  - 并发写，最新的覆盖旧的
- 使用场景
  - 持久性要求不高：如缓存系统
- **确保LWW安全无副作用的唯一方法是**：只写入一次然后写入值视为不可变，这样就避免了对同一个主键的并发（覆盖）写（比如用UUID作为主键）。（在客户端看来，主键是Key，但是服务端存储时是用主键生成的UUID。）
  - KEY（用户视角）/UUID/版本之间的关系思考下。
    - （KEY,版本号）===找到==》UUID===找到==》Value
#### **方法2：通过算法区分并发和Happens-before**
- 实现起来很复杂。下面只是简单例子，帮助体会下
- 太复杂了我去

> Happens-before和并发
- 如何判断两个操作是不是并发呢？
  - 并发：操作是否在时间上重叠并不重要。如果两个操作并不需妥意识到对方，我们即可声称它们是并发操作 
  - Happens-before：一个操作发生之前知道另一个操作已经发生

> 例子
- 单副本
<div align="center" style="zoom:70%"><img src="./pic/2-12.png"></div>
<div align="center" style="zoom:70%"><img src="./pic/2-13.png"></div>

- 算法步骤：
<div align="center" style="zoom:70%"><img src="./pic/2-14.png"></div>

> 版本矢量
- p181
- 副本的版本号。

# 第六章：数据分区
- 分区：
  - 每一条数据（或者每条记录，每行或每个文档）只属于某个特定分区
  - 每个分区都可以视为一个完整的**小型数据库** ，虽然"数据库"可能存在一些跨分区的操作
  - **主要目的**：将**数据**（大小）和**查询负载**均匀分布在所有节点上
    - 不均匀===》倾斜===》出现系统热点
  - `数据<---映射(分区策略)--->分区<---映射(路由)--->节点`
- 考虑的问题
  - 数据怎么分区
    - 如何使数据和查询均匀
  - 索引怎么影响分区
    - 二级索引与分区
  - 分区再平衡
  - 节点路由
    - 服务发现

> 分区与复制
- 每个分区在多个节点存有副本。（小数据库就是了）
- 每个分区都有自己的主副本
<div align="center" style="zoom:70%"><img src="./pic/2-15.png"></div>

## 怎么分区
### 键值数据的分区
#### **基于关键字区间分区**
<div align="center" style="zoom:70%"><img src="./pic/2-16.png"></div>

- 优点：轻松支持区间查询
- 缺点：容易导致热点。(如吴亦凡关键字)
  - 解决p192
#### **基于关键字哈希值分区**
- 优点：数据均匀，查询相对均匀（逃不过单关键字超热点，如吴亦凡）
- 缺点：丧失良好区间性
<div align="center" style="zoom:70%"><img src="./pic/2-17.png"></div>

> 折中：组合索引
- 比如Cassandra：表可以声明为由多个列组成的**复合主键**。复合主键只有**第一部分可用于哈希分区**，而其他列则用作组合索引来对Cassandra SSTable中的数据进行排序。
  - eg：（user_id,update_timestamp）,不同的用户可以存储在不同的分区上，但是对于某一用户，消息按时间戳顺序存储在一个分区上。

> 哈希分区无法完全避免热点
- 比如超热关键字
  - 解决：通过应用层。一个关键字后加个东西，让他在数据库看来不是同一个关键字。
    - 缺点：读需要从多个分区读，后合并

## 分区与二级索引
- 二级索引技术也是 Solr 和 Elasticsearch等全文索引服务器存在之根本
  - 看的时候，有些东西的理解可以从全文索引数据库的角度去想
- 二级索引带来的主要挑战是它们**不能规整**的地映射到分区中
  - 这一块那一块的

### 基于文档分区的二级索引
- 每个列表都有一个**唯一的文档ID**，用此ID对数据库进行分区
- 每个分区**完全独立**，**各自维护**自己的二级索引
- 检索方式：**分散/聚集**
  - 如果想要搜索红色汽车，就需要将查询发送到所有的分区，然后合并所有返回的结果。
  - 缺点：**读放大，读取低效**。即使采用并行，也会容易导致读延迟显著放大（性能受置于最慢的）

<div align="center" style="zoom:70%"><img src="./pic/2-18.png"></div>

### 基于词条的二级索引分区
- 对所有的数据**构建全局索引**
- 全局索引也必须进行分区
  - 分区方式同键值数据分区
- 优点：读取更为高效
- 缺点：写入速度较慢且非常复杂。
  - 一个文档更新，涉及多个二级索引，二级索引分区可能在不同节点上，**写放大**。**所以现有的数据库都不支持同步更新二级索引**
- 实践中，对全局二级索引的更新往往都是异步的
<div align="center" style="zoom:70%"><img src="./pic/2-19.png"></div>

## 分区再平衡
- 针对的是负载。
- 原因：1.压力增加，加节点；2.数据规模增加，加节点；3.故障了，加节点；===》节点变化===》数据迁移
- **再平衡**：迁移负载的过程称为再平衡。
- **基本要求**
  - 要能正常读写
  - 要比原来更加的均匀
  - 要减少不必要的迁移。eg：**为什么hash之后不取模**
- **动态再平衡的策略**
  - 固定数量的分区
  - 动态分区
  - 按节点比例分区
- 自动还是手动再平衡
  - p201

### 固定数量的分区
- **特征**：**分区数量固定**。
  - 分区的大小和数据集大小成正比
- 方案：
  - 首先，分区数 远大于 节点数，然后为每个节点分配多个分区。
    - 如：10节点，1000分区，每节点100个分区（主分区）
  - 接下来，如果增加节点。从其他节点随机拿分区，直到再次平衡。
- 优点：简单。这里唯一要调整的是路由关系。
- 局限：
  - **分区数难定**。如果数据集的总规模高度不确定或可变（例如，开始非常小，但随着时间的推移可能会变得异常庞大）， 此时如何选择合适的分区数就有些困难。
  - **关键字区间分区边界设置 难定**。
    - 搞不好热点严重
<div align="center" style="zoom:70%"><img src="./pic/2-20.png"></div>

### 动态分区
- 特征：分区数动态
  - 分区数量和数据集大小成正比
- 方案
  - 给一个初始分区（预分裂）：避免前期都往一个分区挤
  - 拆分也阈值
  - 合并也阈值

- 优点：自适应
- 缺点：复杂

- 哈希分区和关键字区间分区都可以
### 按节点比例分区
- 特征：分区的数量与节点数成正比（前面两种都无关）
  - 每个节点具有固定数量的分区
  - 节点数不变，分区大小与数据集大小成正比。
  - 节点增，分区大小变小
- 方案
  - 新节点加入，随机选择固定数量的现有分区进行**分裂**，然后**拿走这些分区的一半数据量**，将另一半数据留在原节点
- 前提：基于哈希分区

## 请求路由
- **本质**：服务发现问题
- 三种方式
<div align="center" style="zoom:70%"><img src="./pic/2-21.png"></div>

> 依靠独立的协调服务（如ZooKeeper）
<div align="center" style="zoom:70%"><img src="./pic/2-22.png"></div>

> 节点之间使用gossip协议同步群集状态的变化
- 方式1
- p203